# ResNet_CIFAR-10
使用 ResNet 网络训练 CIFAR-10 数据集

## 1. `CIFAR-10` 数据集

`CIFAR-10` 数据集由 10 个类的 60000 个尺寸为 `32x32` 的 `RGB` 彩色图像组成，每个类有 6000 个图像， 有 50000 个训练图像和 10000 个测试图像。

## 2. 数据增强

为了提高模型的泛化性，防止训练时在训练集上过拟合，往往在训练的过程中会对训练集进行数据增强操作，例如随机翻转、遮挡、填充后裁剪等操作。我们这里对训练集做如下三种处理：

### （1）随机翻转
代码如下：

```python
transforms.RandomHorizontalFlip()
```

### （2）填充后随机裁剪

我们可以将尺寸为 `32x32` 的图像填充为 `40x40`，然后随机裁剪成 `32x32`。
```python
transforms.RandomCrop(32, padding=4)
```

### （3）Cutout操作

Cutout操作会随机遮挡图片的若干尺寸的若干块，尺寸和块可以根据自己的需要设置。

调用代码如下，这里我们设置块为 1，尺寸长度为 16 个像素。cutout 的完整操作将在后面给出。Github 链接：https://github.com/uoguelph-mlrg/Cutout

```python
Cutout(n_holes=1, length=16)
```

## 3. 修改 `ResNet` 模型

考虑到 `CIFAR10` 数据集的图片尺寸太小，`ResNet` 网络的 `7x7` 降采样卷积和池化操作容易丢失一部分信息，所以在实验中我们将 `7x7` 的降采样层和最大池化层去掉，替换为一个 `3x3` 的降采样卷积，同时减小该卷积层的步长和填充大小，这样可以尽可能保留原始图像的信息。

**删去最大池化层 MaxPool**


## 4. 训练策略

- 共训练 300 个 epoch。在训练中，我们的 batch_size 大小为 128，优化器为 `SGD`。
- 使用 CosineAnnealing 学习率调度器
